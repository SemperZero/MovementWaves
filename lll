import plotly.graph_objects as go
import pandas as pd
import numpy as np
import plotly.figure_factory as ff
import plotly.colors
import plotly.offline as pyo
import plotly.express as px
import os
from sklearn.manifold import TSNE
from PIL import Image
import io
import pickle
from sklearn.cluster import KMeans
from sklearn.cluster import DBSCAN
from hover import *

SAVE_HTMLS = True
HISTNORM = None # "probability"

def concat_images_vertical(imgs, crop0, crop1):
    #imgs = [Image.open(io.BytesIO(png_img)) for png_img in png_images if png_img is not None]
    imgs[0] = imgs[0].crop((crop0[0],crop0[1],imgs[0].width-crop0[2], imgs[0].height-crop0[3]))
    imgs[1] = imgs[1].crop((crop1[0],crop1[1],imgs[1].width-crop1[2], imgs[1].height-crop1[3]))


    if len(imgs) == 0:
        return None, None

    
    width = max([img.width for img in imgs])
    height = sum([img.height for img in imgs])

    concatenated_image = Image.new('RGBA', (width, height))
    concatenated_image.paste( (0,0,0), (0, 0, width, height))

    current_height = 0
    for img in imgs:
        concatenated_image.paste(img, (0, current_height))
        current_height+=img.height

    #buffer = io.BytesIO()
    
    #concatenated_image.save(os.path.join(folder_path, "concatenated%d.png"%label))
    #concatenated_image.save(buffer, format="png")
    
    return concatenated_image, current_height #need to return

def concat_images_horizontal(imgs, crop0, crop1):
    #print(len(png_images))
   # imgs = [Image.open(io.BytesIO(png_img)) for png_img in png_images if png_img is not None]
    imgs[0] = imgs[0].crop((crop0[0],crop0[1],imgs[0].width-crop0[2], imgs[0].height-crop0[3]))
    imgs[1] = imgs[1].crop((crop1[0],crop1[1],imgs[1].width-crop1[2], imgs[1].height-crop1[3]))


    if len(imgs) == 0:
        return None, None


    #imgs = [img.crop((border_size, crop_top, img.width - border_size, img.height - border_size)) for img in imgs]
    
    width = sum([img.width for img in imgs])
    height = max([img.height for img in imgs])

    concatenated_image = Image.new('RGBA', (width, height))
    concatenated_image.paste( (0,0,0), (0, 0, width, height))

    current_width = 0
    for img in imgs:
        concatenated_image.paste(img, (current_width, 0))
        current_width+=img.width

    #buffer = io.BytesIO()
    
    #concatenated_image.save(os.path.join(folder_path, "concatenated%d.png"%label))
    #concatenated_image.save(buffer, format="png")
    
    return concatenated_image, current_width #need to return

def get_histogram_latency(df, region_name):
    fig = go.Figure()
    column_name = "e2EDurationInMilliseconds"
    histogram_trace = go.Histogram(x=df[column_name], xbins=dict(start=0, end=df[column_name].max(), size=40),
                                marker_color='yellow', opacity=0.7)#, histnorm='probability')
    fig.add_trace(histogram_trace)
    fig.update_layout(
        xaxis_title=column_name,
        yaxis_title='Frequency normalized',
        template = "plotly_dark",
        bargap=0.1,
        title = f"Latency Distribution {region_name}"
        # xaxis_range = [0, 15000]
    )
    fig.show()

def plot_latency_histograms_regions(df):
    regions = np.unique(df["region"].values) #['CanadaCentral', 'SwitzerlandNorth', 'australiaeast', 'eastus2', 'southeastasia', 'westeurope', 'westus2']
    for region_name in regions:
        r_df = df[df["region"] == region_name]
        get_histogram_latency(r_df, region_name)

def plot_latency_histograms_split(df, filter_column, pre_title = ""):

    fig = go.Figure()
    column_name = "e2EDurationInMilliseconds"

    split_names = df[filter_column].unique() #['CanadaCentral', 'SwitzerlandNorth', 'australiaeast', 'eastus2', 'southeastasia', 'westeurope', 'westus2']
   # print(split_names)
    for split_name in split_names:
        r_df = df[df[filter_column] == split_name]
        fig.add_trace(go.Histogram(x=r_df[column_name], xbins=dict(start=0, end=r_df[column_name].max(), size=40),
                                     opacity=0.7, name = split_name, bingroup=1, histnorm=HISTNORM))
    
    fig.update_layout(
        xaxis_title=column_name,
        yaxis_title='Frequency normalized',
        template = "plotly_dark",
        bargap=0.1,
        title = f"Latency Distribution |{pre_title} {filter_column}",
        # xaxis_range = [0, 15000]
        # barmode="overlay"
    )
    
    if SAVE_HTMLS:
        pyo.plot(fig, filename=f"saved_graphs\\histograms_split_{filter_column}.html")
    else:
        fig.show()

def plot_latency_histograms_double_split(df, filter_column, secondary_fiter):
    split_names = df[filter_column].unique() 
    for split_name in split_names:
        r_df = df[df[filter_column] == split_name]
        print(split_name, len(r_df))
        plot_latency_histograms_split(r_df, secondary_fiter, f" {filter_column} = {split_name} | ")

def plot_latency_histograms_double_split_select(df, filter_column, filter_name, secondary_fiter):
    split_name =filter_name
    r_df = df[df[filter_column] == split_name]
    print(filter_name, len(r_df))
    plot_latency_histograms_split(r_df, secondary_fiter, f" {filter_column} = {split_name} | ")

def plot_latency_dist_bars_split(df, filter_column):

    fig = go.Figure()
    column_name = "e2EDurationInMilliseconds"
    split_names = np.unique(df[filter_column].values) #['CanadaCentral', 'SwitzerlandNorth', 'australiaeast', 'eastus2', 'southeastasia', 'westeurope', 'westus2']

    dfs = []
    for split_name in split_names:
        r_df = df[df[filter_column] == split_name]
        dfs.append(r_df)
    
    distplots = ff.create_distplot([r_df[column_name] for r_df in dfs], split_names, show_hist=False, show_curve=True, bin_size=40, histnorm=HISTNORM)['data']
    for distplot in distplots:
        fig.add_trace(distplot)
    
    fig.update_layout(
        xaxis_title=column_name,
        yaxis_title='Frequency normalized',
        template = "plotly_dark",
        bargap=0.1,
        title = f"Latency Distribution {filter_column}",
        # xaxis_range = [0, 15000]
       # barmode="overlay"
    )
    
    if SAVE_HTMLS:
        pyo.plot(fig, filename=f"saved_graphs\\dist_bars_split_{filter_column}.html")
    else:
        fig.show()

def plot_latency_split_approx_distrib(df, filter_column, pre_title = ""):
    fig = go.Figure()
    column_name = "e2EDurationInMilliseconds"
    split_names = np.unique(df[filter_column].values) #['CanadaCentral', 'SwitzerlandNorth', 'australiaeast', 'eastus2', 'southeastasia', 'westeurope', 'westus2']

    colors = plotly.colors.sequential.Rainbow
    while len(colors) < len(split_names):
        colors += colors

    
    #for i, split_name in enumerate(split_names):
        #r_df = df[df[filter_column] == split_name]
        #fig.add_trace(go.Histogram(x=r_df[column_name], xbins=dict(start=0, end=r_df[column_name].max(), size=40),
        #                             opacity=0.7, histnorm='probability', name = split_name, bingroup=1))
        
        #fig.add_trace(ff.create_distplot([r_df[column_name]], [split_name], colors = [colors[i]], show_hist=True, show_curve=True, bin_size=40)['data'][0])
    
    x_vals = []
    labels = []
    for split_name in split_names:
        x_vals.append(df[df[filter_column] == split_name][column_name].values)
        labels.append(split_name)

    fig= ff.create_distplot(x_vals, labels, bin_size=40, colors = colors)
    
    fig.update_layout(
        xaxis_title=column_name,
        yaxis_title='Frequency normalized',
        template = "plotly_dark",
        bargap=0.1,
        title = f"Latency Distribution |{pre_title} {filter_column}",
        # xaxis_range = [0, 15000]
       # barmode="overlay"
    )

    if SAVE_HTMLS:
        pyo.plot(fig, filename=f"saved_graphs\\histograms_split_distrib_{filter_column}.html")
    else:
        fig.show()

def plot_latency_approx_distrib_double_split(df, filter_column, secondary_fiter):
    split_names = df[filter_column].unique() 
    for split_name in split_names:
        r_df = df[df[filter_column] == split_name]
        plot_latency_split_approx_distrib(r_df, secondary_fiter, f" {filter_column} = {split_name} | ")


def get_histogram_time_buckets_average(df):
    df['PreciseTimeStamp'] = pd.to_datetime(df['PreciseTimeStamp'])

    column_name = "e2EDurationInMilliseconds"
    split_name = 'region'
    grouped_df = df.groupby(['region', pd.Grouper(key='PreciseTimeStamp', freq='1H')])[column_name].mean().reset_index()

    fig = go.Figure()

    grouped_df = df.groupby([split_name, pd.Grouper(key='PreciseTimeStamp', freq='1H')])[column_name].mean().reset_index()

    fig = px.histogram(grouped_df, x='PreciseTimeStamp', y=column_name, color=split_name,
                    labels={column_name: 'Average Latency', 'PreciseTimeStamp': 'Time Bucket'},
                    title='Histogram of Averages of Latency in 1-hour Buckets',
                    histfunc='avg',  # Optional: Set to 'avg' to show averages
                    barmode='group',
                    template='plotly_dark')  # Optional: Set to 'overlay' for overlaid bars

    fig.show()

def get_histogram_time_density_nr_requests1(df):
    df['PreciseTimeStamp'] = pd.to_datetime(df['PreciseTimeStamp'])

    column_name = "e2EDurationInMilliseconds"
    split_name = 'region'
    grouped_df = df.groupby(['region', pd.Grouper(key='PreciseTimeStamp', freq='1H')])[column_name].count().reset_index()

    fig = go.Figure()

    grouped_df = df.groupby([split_name, pd.Grouper(key='PreciseTimeStamp', freq='1H')])[column_name].count().reset_index()

    fig = px.histogram(grouped_df, x='PreciseTimeStamp', y=column_name, color=split_name,
                    labels={column_name: 'Count Requests', 'PreciseTimeStamp': 'Time Bucket'},
                    title='Histogram of Count Requests in 1-hour Buckets',
                    histfunc='avg',  # Optional: Set to 'avg' to show averages
                    barmode='group',
                    template='plotly_dark')  # Optional: Set to 'overlay' for overlaid bars

    fig.show()

def get_histogram_time_density_nr_requests2(df, filter_column, filter_name):
    df['PreciseTimeStamp'] = pd.to_datetime(df['PreciseTimeStamp'])
    df['PreciseTimeStamp'] = df['PreciseTimeStamp'].dt.floor('1H')

    column_name = "e2EDurationInMilliseconds"
    split_name = 'region'
    
    #grouped_df = df.groupby(['region', pd.Grouper(key='PreciseTimeStamp', freq='1H')])[column_name].count().reset_index()
    
    
    fig = go.Figure()
    column_name = "e2EDurationInMilliseconds"
    df = df[df[filter_column] == filter_name]

    #colors = plotly.colors.sequential.Rainbow
    #while len(colors) < len(split_names):
    #    colors += colors

    split_names = [str(s) for s in np.unique(df['PreciseTimeStamp'])]
    dfs = []
    for split_name in np.unique(df['PreciseTimeStamp']):
        r_df = df[df['PreciseTimeStamp'] == split_name]
        dfs.append(r_df)
    
    distplots = ff.create_distplot([r_df[column_name] for r_df in dfs], split_names, show_hist=False, show_curve=True, bin_size=40, histnorm=HISTNORM)['data']
    for distplot in distplots:
        fig.add_trace(distplot)

    # for i, split_name in :
    #     r_df = df[df['PreciseTimeStamp'] == split_name]
    #     print(r_df)
    #     #fig.add_trace(go.Histogram(x=r_df[column_name], xbins=dict(start=0, end=r_df[column_name].max(), size=40),
    #      #                            opacity=0.7, histnorm=HISTNORM, name = split_name, bingroup=1))
        
    #     fig.add_trace(ff.create_distplot([r_df[column_name]], [str(split_name)], show_hist=False, show_curve=True, bin_size=40)['data'][0])
    
    
    fig.update_layout(
        xaxis_title=column_name,
        yaxis_title='Frequency normalized',
        template = "plotly_dark",
        bargap=0.1,
        title = f"Latency Distribution {filter_column}",
        # xaxis_range = [0, 15000]
       # barmode="overlay"
    )
    fig.show()

def label_dataset_filter_sets(df, filters_list):
    combined_categories = df[filters_list[0]]
    for f in filters_list[1:]:
        combined_categories = combined_categories + "_" + df[f]
    labels, unique_values = pd.factorize(combined_categories)
    df['SetLabels'] = labels
    df['combined_categories'] = combined_categories
    df.to_parquet(r"D:\programming\micro\latency\data\query2.parquet")

def plot_evolution0(df):

    fig = go.Figure()
    df = df.sort_values(by='PreciseTimeStamp')

    fig.add_trace(go.Scatter(x = list(range(len(df))), y = df["PreciseTimeStamp"], mode = "markers", marker = dict(color=  df["SetLabels"].values, colorscale  = "rainbow")))
    #fig = px.scatter(df, x = list(range(len(df))), y = "PreciseTimeStamp", hover_data="region")
    fig.update_layout(template = "plotly_dark")
    fig.show()

def plot_evolution(df):
    fig = go.Figure()

    df = df.sort_values(by='PreciseTimeStamp')
    fig.add_trace(go.Scatter(x = list(range(len(df))), y = df["PreciseTimeStamp"], mode = "markers", marker = dict(color=  df["SetLabels"].values, colorscale  = "rainbow")))
    fig.update_layout(template = "plotly_dark")
    fig.show()

def plot_set_evolution(df):
    
    df = df.sort_values(by='PreciseTimeStamp')

    fig = go.Figure()
    for set_label in df["SetLabels"].unique():
        f_df = df[df["SetLabels"] == set_label]
        fig.add_trace(go.Scatter(x = f_df["PreciseTimeStamp"], y = f_df["e2EDurationInMilliseconds"], mode = "lines"))
    fig.update_layout(template = "plotly_dark")
    fig.show()

def plot_latency_histograms_evolution(full_df, filter_column):
    full_df["PreciseTimeStamp"] = pd.to_datetime(full_df["PreciseTimeStamp"])
    full_df = full_df.sort_values(by='PreciseTimeStamp')
    full_df['PreciseTimeStamp'] = pd.to_datetime(full_df['PreciseTimeStamp'], format = '%Y-%m-%d %H:%M')

   # exit()
    BUCKET_SIZE = 10000
    STEP_SIZE = 500
    frame_nr = 0
    split_names = full_df[filter_column].unique()


    
    
    time_range = pd.date_range(start=full_df["PreciseTimeStamp"].min(), end=full_df["PreciseTimeStamp"].max(), freq='240S')
    interval_delta = pd.Timedelta(hours=2)

    #for k in range(0, len(full_df)-BUCKET_SIZE, STEP_SIZE):
       # df = full_df[k : k + BUCKET_SIZE]
    for interval_start in time_range:
        interval_start = pd.to_datetime(interval_start)
        
        start_time = interval_start
        end_time = interval_start + interval_delta
       # print(full_df['PreciseTimeStamp'][0])
       # print(type(start_time))
       # exit()
        df = full_df[(full_df['PreciseTimeStamp'] >= start_time) & (full_df['PreciseTimeStamp'] <= end_time)]
        df['PreciseTimeStamp'] = df['PreciseTimeStamp'].dt.strftime('%Y-%m-%d %H:%M')

        fig = go.Figure()
        column_name = "e2EDurationInMilliseconds"

        for split_name in split_names:
            r_df = df[df[filter_column] == split_name]

            # xrange = list(range(r_df[column_name].min(), r_df[column_name].max(), 400))
            # #print(r_df[column_name].min(), r_df[column_name].max())
            # yrange = [0] * len(xrange)
            # for x in r_df[column_name].values:
            #     yrange[(x-r_df[column_name].min())//400] += 1
            # fig.add_trace(go.Bar(x=xrange, y = yrange,
            #                             opacity=0.7, name = split_name))

            fig.add_trace(go.Histogram(x=r_df[column_name], xbins=dict(start=0, end=r_df[column_name].max(), size=40),
                                         opacity=0.7, name = split_name, bingroup=1, histnorm=HISTNORM))
        
        
        # colors = plotly.colors.sequential.Rainbow
        # while len(colors) < len(split_names):
        #     colors += colors
        # for i, split_name in enumerate(split_names):
        #     r_df = df[df[filter_column] == split_name]
        # # fig.add_trace(go.Histogram(x=r_df[column_name], xbins=dict(start=0, end=r_df[column_name].max(), size=40),
        # #                             opacity=0.7, histnorm='probability', name = split_name, bingroup=1))
        #     distplot = ff.create_distplot([r_df[column_name]], [split_name], colors = [colors[i]], show_hist=True, show_curve=True, bin_size=100, histnorm = "probability")
        #     fig.add_trace(distplot['data'][0])
        #     fig.add_trace(distplot['data'][1])



        fig.update_layout(
            xaxis_title=column_name,
            yaxis_title='Frequency normalized',
            template = "plotly_dark",
            bargap=0.0001,
            title = f"Latency Distribution {filter_column} | time range = [{df['PreciseTimeStamp'].min()} -> {df['PreciseTimeStamp'].max()}]",
            xaxis_range = [0, 100000],
            yaxis_range = [0, 30],
            #yaxis_range = [0, 0.07],
            width = 1500,
            height = 1500
            # barmode="overlay"
        )
        
        frame_nr+=1
       # fig.show()
       # exit()
        fig.write_image(f"animations\\dist_evol\\region\\5\\{frame_nr:04}.jpg")

def plot_set_evolution_fft(df):
    
    
    df['PreciseTimeStamp'] = pd.to_datetime(df['PreciseTimeStamp'])
    df = df.sort_values(by='PreciseTimeStamp')
    df['PreciseTimeStamp'] = df['PreciseTimeStamp'].dt.floor('1S')

   
    colors = plotly.colors.sequential.Rainbow
    while len(colors) < len(df["SetLabels"].unique()):
        colors += colors

    

    fig = go.Figure()
    i=0
    for set_label in df["SetLabels"].unique():
        
        f_df = df[df["SetLabels"] == set_label]
        smooth_time_range = pd.date_range(start=f_df["PreciseTimeStamp"].min(), end=f_df["PreciseTimeStamp"].max(), freq='1S')

        yvals = {t:None for t in smooth_time_range}

        for t, lat in zip(f_df["PreciseTimeStamp"], f_df["e2EDurationInMilliseconds"]):
            yvals[t] = lat

        interp_df = pd.DataFrame({"timestamp" : smooth_time_range, "vals" :list(yvals.values()) })
        interp_df.set_index('timestamp', inplace=True)

        interp_df = interp_df.interpolate(method='linear')
        interp_df.reset_index(inplace=True)
       # print(interp_df["vals"])
        fft_result = np.fft.fft(interp_df["vals"])
        num_components = 8
        fft_result[num_components+1:] = 0
        approximated_signal = np.fft.ifft(fft_result).real
       # print(approximated_signal)
        fig.add_trace(go.Scatter(x = interp_df["timestamp"], y = interp_df["vals"], mode = "lines", opacity = 0.5, line = dict(color = colors[i])))
        fig.add_trace(go.Scatter(x = interp_df["timestamp"], y = approximated_signal, mode = "lines", line = dict(color = colors[i])))
        i+=1
    fig.update_layout(template = "plotly_dark")
    fig.show()

def build_rolling_fft(full_df):
    num_components = 10
    
    full_df['PreciseTimeStamp'] = pd.to_datetime(full_df['PreciseTimeStamp'])
    full_df = full_df.sort_values(by='PreciseTimeStamp')
    full_df['PreciseTimeStamp'] = full_df['PreciseTimeStamp'].dt.floor('1S')

    set_labels = full_df["SetLabels"].unique()[3:4]

    colors = plotly.colors.sequential.Rainbow
    while len(colors) < len(set_labels):
        colors += colors

    

    
    # time_range = pd.date_range(start=full_df["PreciseTimeStamp"].min(), end=full_df["PreciseTimeStamp"].max(), freq='240S')
    # time_bucket = pd.Timedelta(hours=2)
    time_range = pd.date_range(start=full_df["PreciseTimeStamp"].min(), end=full_df["PreciseTimeStamp"].max(), freq='10S')
    time_bucket = pd.Timedelta(seconds = 60)
    fft_matrices = {set_label : [] for set_label in set_labels}

    big_matrix = []
    all_labels = []


    for interval_start in time_range:
        interval_start = pd.to_datetime(interval_start)
        
        start_time = interval_start
        end_time = interval_start + time_bucket

        df = full_df[(full_df['PreciseTimeStamp'] >= start_time) & (full_df['PreciseTimeStamp'] <= end_time)]
       
        for set_label in set_labels:
            
            f_df = df[df["SetLabels"] == set_label]
            if len(f_df) == 0:
               # fft_matrices[set_label].append(np.full((2*num_components), np.nan))
                continue
            
            smooth_time_range = pd.date_range(start=f_df["PreciseTimeStamp"].min(), end=f_df["PreciseTimeStamp"].max(), freq='1S')

            yvals = {t:None for t in smooth_time_range}

            for t, lat in zip(f_df["PreciseTimeStamp"], f_df["e2EDurationInMilliseconds"]):
                yvals[t] = lat

            interp_df = pd.DataFrame({"timestamp" : smooth_time_range, "vals" :list(yvals.values()) })
            interp_df.set_index('timestamp', inplace=True)

            interp_df = interp_df.interpolate(method='linear')
            interp_df.reset_index(inplace=True)

            fft_result = np.fft.fft(interp_df["vals"])
            
            fft_result[num_components+1:] = 0
            #approximated_signal = np.fft.ifft(fft_result).real
            amplitudes = np.abs(fft_result[:num_components])
            phases = np.angle(fft_result[:num_components])
            
            amplitudes = np.pad(amplitudes, (0, num_components - len(amplitudes)), constant_values=np.nan)
            phases = np.pad(phases, (0, num_components - len(phases)), constant_values=np.nan)


            fft_matrices[set_label].append(np.concatenate((amplitudes, phases)))
                
           # nan_count = np.sum(np.isnan(fft_matrices[set_label]))
            #print(nan_count)
          #  if nan_count!=0:
              #  print(nan_count)
               # print((amplitudes, phases))
            


    return fft_matrices

def plot_tsne_fft(df):
    #df = df[1000:3000]
    fft_matrices = build_rolling_fft(df)
    
    labels = []
    for set_l in fft_matrices:
        fft_matrices[set_l] = np.vstack(fft_matrices[set_l])
        shape = fft_matrices[set_l].shape#all shapes are the same. add check
        
        labels += [set_l]*len(fft_matrices[set_l])

    big_matrix = np.empty(shape)
    for set_l in fft_matrices:
        big_matrix = np.vstack((big_matrix, fft_matrices[set_l]))
    
    
    nan_count = np.sum(np.isnan(big_matrix))
    
    print("nan percent", nan_count / (big_matrix.shape[0]* big_matrix.shape[1]) )
    
    big_matrix = np.nan_to_num(big_matrix, nan=0.0)
    print(big_matrix.shape)
    #exit()
    print(big_matrix)
    #exit()

        

    #print(labels)

    #exit()

    tsne_model = TSNE(n_components = 3, n_jobs = 8, random_state = 42, perplexity = 23)
    tsne_transform = tsne_model.fit_transform(big_matrix)
    
    fig = go.Figure()
    fig.add_trace(go.Scatter3d(x = tsne_transform[:, 0], y = tsne_transform[:, 1], z = tsne_transform[:, 2], marker = dict(size = 4, color=  labels, colorscale  = "rainbow"), line = dict(color=  labels, colorscale  = "rainbow")))
    fig.update_layout(template = "plotly_dark")
    fig.show()
    #pyo.plot(fig, filename=f"saved_graphs\\tsne_fft.html")

def get_distrib(vals, max_latency = 4_000_000):
    bucket_size = 40
    x_bins = [0 for x in range(0, max_latency, bucket_size)]
    for x in vals:
        x_bins[x//bucket_size]+=1
    x_bins = np.array(x_bins)
    x_bins = x_bins/np.sum(x_bins)

    return x_bins

def build_rolling_fft_ordered(full_df, set_labels):
    num_components = 10
    
    full_df['PreciseTimeStamp'] = pd.to_datetime(full_df['PreciseTimeStamp'])
    full_df = full_df.sort_values(by='PreciseTimeStamp')
    full_df['PreciseTimeStamp'] = full_df['PreciseTimeStamp'].dt.floor('1S')

    max_latency = full_df["e2EDurationInMilliseconds"].max()

    colors = plotly.colors.sequential.Rainbow
    while len(colors) < len(set_labels):
        colors += colors

    fft_df = {}
    for set_label in set_labels:
        fft_df[f"{set_label}_fft"] = []
        fft_df[f"{set_label}_values"] = []
        fft_df[f"{set_label}_distrib"] = []
        fft_df[f"{set_label}_interp"] = []
        fft_df[f"{set_label}_approximated_signal"] = []

    for col_name in ["time_start", "time_end", "index"]:
        fft_df[col_name] = []
    
    # time_range = pd.date_range(start=full_df["PreciseTimeStamp"].min(), end=full_df["PreciseTimeStamp"].max(), freq='240S')
    # time_bucket = pd.Timedelta(hours=2)
    time_range = pd.date_range(start=full_df["PreciseTimeStamp"].min(), end=full_df["PreciseTimeStamp"].max(), freq='10S')
    time_bucket = pd.Timedelta(seconds = 60)
    fft_matrices = {set_label : [] for set_label in set_labels}

    big_matrix = []
    all_labels = []

    index = 0
    for interval_start in time_range:
        interval_start = pd.to_datetime(interval_start)
        
        start_time = interval_start
        end_time = interval_start + time_bucket

        df = full_df[(full_df['PreciseTimeStamp'] >= start_time) & (full_df['PreciseTimeStamp'] <= end_time)]
        fft_df["time_start"].append(start_time)
        fft_df["time_end"].append(end_time)
        fft_df["index"].append(index)
        index+=1

        for set_label in set_labels:
            
            f_df = df[df["SetLabels"] == set_label]
            if len(f_df) == 0:
                fft_df[f"{set_label}_fft"].append(np.nan)
                fft_df[f"{set_label}_interp"].append(np.nan)
                fft_df[f"{set_label}_values"].append(np.nan)
                fft_df[f"{set_label}_distrib"].append(np.nan)
                fft_df[f"{set_label}_approximated_signal"].append(np.nan)


                continue
            
            smooth_time_range = pd.date_range(start=f_df["PreciseTimeStamp"].min(), end=f_df["PreciseTimeStamp"].max(), freq='1S')

            yvals = {t:None for t in smooth_time_range}

            for t, latency in zip(f_df["PreciseTimeStamp"], f_df["e2EDurationInMilliseconds"]):
                yvals[t] = latency

            interp_df = pd.DataFrame({"timestamp" : smooth_time_range, "vals" :list(yvals.values()) })
            interp_df.set_index('timestamp', inplace=True)

            interp_df = interp_df.interpolate(method='linear')
            interp_df.reset_index(inplace=True)

            fft_result = np.fft.fft(interp_df["vals"])
            
            fft_result[num_components+1:] = 0
            approximated_signal = np.fft.ifft(fft_result).real
            amplitudes = np.abs(fft_result[:num_components])
            phases = np.angle(fft_result[:num_components])
            
            amplitudes = np.pad(amplitudes, (0, num_components - len(amplitudes)), constant_values=np.nan)
            phases = np.pad(phases, (0, num_components - len(phases)), constant_values=np.nan)


            #fft_matrices[set_label].append(np.concatenate((amplitudes, phases)))


            fft_df[f"{set_label}_fft"].append(np.concatenate((amplitudes, phases)))
            fft_df[f"{set_label}_interp"].append(interp_df["vals"].values)
            fft_df[f"{set_label}_values"].append(f_df["e2EDurationInMilliseconds"].values)
            fft_df[f"{set_label}_distrib"].append(get_distrib(f_df["e2EDurationInMilliseconds"].values, max_latency))
            fft_df[f"{set_label}_approximated_signal"].append(approximated_signal)
           # nan_count = np.sum(np.isnan(fft_matrices[set_label]))
            #print(nan_count)
          #  if nan_count!=0:
              #  print(nan_count)
               # print((amplitudes, phases))
            


    return fft_df, set_labels

def build_tsne_train_matrix(fft_df, set_labels):
    tsne_labels = []
    tsne_indexes_map = [] # 
    big_matrix = []
    for set_l in set_labels:
        for index, fft_components in zip(fft_df["index"].values, fft_df[f"{set_l}_fft"].values):
            if fft_components is np.nan:
                pass
            else:
                big_matrix.append(fft_components)
                tsne_indexes_map.append(index)
                tsne_labels.append(set_l)

    #print(tsne_indexes_map)
   # exit()
    big_matrix = np.vstack(big_matrix)
    nan_count = np.sum(np.isnan(big_matrix))
    
    print("nan percent", nan_count / (big_matrix.shape[0]* big_matrix.shape[1]) )
    big_matrix = np.nan_to_num(big_matrix, nan=0.0)
    print(big_matrix.shape)
    return big_matrix, tsne_indexes_map, tsne_labels

def plot_tsne_fft_ordered(df, do_plot = False, save_data = False):
    #df = df[1000:3000]
    set_labels = df["SetLabels"].unique()
    combined_categories = df["combined_categories"].unique()
    map_set_name = {}
    for s, c in zip(set_labels, combined_categories):
        map_set_name[s] = c
   # set_labels = [6]
  #  print(set_labels)
 #   exit()
    fft_df, set_labels = build_rolling_fft_ordered(df, set_labels)
    #for x  in fft_df:
    #    print(len(fft_df[x]))
    #exit()
    fft_df = pd.DataFrame(fft_df)
    
    big_matrix, tsne_indexes_map, tsne_labels = build_tsne_train_matrix(fft_df, set_labels)



    tsne_model = TSNE(n_components = 3, n_jobs = 8, random_state = 42, perplexity = 23)
    tsne_transform = tsne_model.fit_transform(big_matrix)
    
    for set_label in set_labels:
        fft_df[f"{set_label}_TSNE"] = [np.nan]*len(fft_df)

    fft_df.set_index('index', inplace=True)
    for i,set_label,x,y,z in zip(tsne_indexes_map, tsne_labels, tsne_transform[:, 0], tsne_transform[:, 1], tsne_transform[:, 2]):
        fft_df.at[i, f"{set_label}_xTSNE"] = x
        fft_df.at[i, f"{set_label}_yTSNE"] = y
        fft_df.at[i, f"{set_label}_zTSNE"] = z

    if save_data:
        fft_df.to_parquet("data\\fft_df.parquet")
        with open('data\\map_set_name.pkl', 'wb') as pickle_file:
            pickle.dump(map_set_name, pickle_file)
        np.save('data\\big_matrix.npy', big_matrix)
        np.save('data\\tsne_transform.npy', tsne_transform)
        np.save('data\\tsne_indexes_map.npy', np.array(tsne_indexes_map))
        np.save('data\\tsne_labels.npy', np.array(tsne_labels))


    if not do_plot:
        return fft_df, set_labels, map_set_name
    

    colors = plotly.colors.sequential.Rainbow
    while len(colors) < len(set_labels):
        colors += colors
    print(tsne_labels)

    # fig = go.Figure()
    # fig.add_trace(go.Scatter3d(x = tsne_transform[:, 0], y = tsne_transform[:, 1], z = tsne_transform[:, 2], marker = dict(size = 4, color=  tsne_labels, colorscale  = "rainbow"), line = dict(color=  tsne_labels, colorscale  = "rainbow")))
    # fig.update_layout(template = "plotly_dark")
    # fig.show()


    
    fig = go.Figure()
    for i, set_label in enumerate(set_labels):
        fig.add_trace(go.Scatter(x = fft_df[f"{set_label}_xTSNE"], y = fft_df[f"{set_label}_yTSNE"], z = fft_df[f"{set_label}_zTSNE"], mode = "markers", 
                                   marker = dict(size = 4, color= colors[i]), line = dict(color = colors[i]),
                                name = map_set_name[set_label]))
    fig.update_layout(template = "plotly_dark")
    fig.show()
  #  pyo.plot(fig, filename=f"saved_graphs\\tsne_fft3.html")
    return fft_df, set_labels, map_set_name

def plot_fft_evolution_tsne(df):
    df['PreciseTimeStamp'] = pd.to_datetime(df['PreciseTimeStamp'])
    df = df.sort_values(by='PreciseTimeStamp')
    df['PreciseTimeStamp'] = df['PreciseTimeStamp'].dt.floor('1S')
    fft_df, set_labels, map_set_name = plot_tsne_fft_ordered(df)

   # print(fft_df["time_start"].min(), fft_df["time_start"].max())
   # exit()
    colors = plotly.colors.sequential.Rainbow
    while len(colors) < len(set_labels):
        colors += colors


    full_start_time = fft_df["time_start"].min()
    full_end_time = fft_df["time_start"].max()
    
    wave_df = df[(df['PreciseTimeStamp'] >= full_start_time) & (df['PreciseTimeStamp'] <= full_end_time)]


    #fig_wave.show()
   


    frame_nr = 0
    # for nr_sec_delta in range(0, 10000, 10):
    #     end_time = start_time + pd.Timedelta(seconds = nr_sec_delta)
    #     segment_fft_df = fft_df[(fft_df['time_start'] >= start_time) & (fft_df['time_start'] <= end_time)]
    
    time_range = pd.date_range(start=fft_df["time_start"].min(), end=fft_df["time_start"].max(), freq='10S')
    time_bucket = pd.Timedelta(seconds = 60)

    for interval_start in time_range:
        interval_start = pd.to_datetime(interval_start)
        
        start_time = interval_start
        end_time = interval_start + time_bucket

        segment_fft_df = fft_df[(fft_df['time_start'] >= full_start_time) & (fft_df['time_start'] <= end_time)]
        fig_tsne = go.Figure()
        #or set xaxis range, y,z ... to the max ever in that column
        fig_tsne.add_trace(go.Scatter3d(x = [-40,-40,-40,-40,40,40,40,40], y = [-40,-40,40,40,-40,-40,40,40], z = [-40,40,-40,40,-40,40,-40,40],opacity = 0, mode = "markers", marker = dict(size = 0)))
        
        for i, set_label in enumerate(set_labels):
            fig_tsne.add_trace(go.Scatter3d(x = segment_fft_df[f"{set_label}_xTSNE"], y = segment_fft_df[f"{set_label}_yTSNE"], z = segment_fft_df[f"{set_label}_zTSNE"], marker = dict(size = 4, color= colors[i]), line = dict(color = colors[i]),
                                   ))# name = map_set_name[set_label]))
        fig_tsne.update_layout(template = "plotly_dark", width = 1500, height = 1500, scene_camera=dict(eye=dict(x=0.5, y=0.5, z=0.5)))

        
        
        


        fig_dist = go.Figure()       
        # for i, set_label in enumerate(set_labels):
        #     f_wave_df = wave_df[wave_df["SetLabels"] == set_label]
        #     f_segment_wave_df = f_wave_df[(f_wave_df['PreciseTimeStamp'] >= start_time) & (f_wave_df['PreciseTimeStamp'] <= end_time)]

        

        fig_wave = go.Figure()
        
        for i, set_label in enumerate(set_labels):
            f_wave_df = wave_df[wave_df["SetLabels"] == set_label]
            smooth_time_range = pd.date_range(start=wave_df["PreciseTimeStamp"].min(), end=wave_df["PreciseTimeStamp"].max(), freq='1S')
            yvals = {t:None for t in smooth_time_range}
            print(list(f_wave_df["PreciseTimeStamp"].values))
            for t, latency in zip(f_wave_df["PreciseTimeStamp"], f_wave_df["e2EDurationInMilliseconds"]):
                yvals[t] = latency

            print(len(smooth_time_range))
            print(len(yvals))

            interp_df = pd.DataFrame({"timestamp" : smooth_time_range, "vals" :list(yvals.values()) })
            interp_df.set_index('timestamp', inplace=True)
            interp_df = interp_df.interpolate(method='linear')
            interp_df.reset_index(inplace=True)
            f_wave_df = interp_df

            f_segment_wave_df = f_wave_df[(f_wave_df['timestamp'] >= start_time) & (f_wave_df['timestamp'] <= end_time)]
           # f_segment_wave_df = segment_wave_df[segment_wave_df["SetLabels"] == set_label]
            

            fig_wave.add_trace(go.Scatter(x = f_wave_df["timestamp"], y = f_wave_df["vals"], mode = "lines", opacity = 0.3, line = dict(color = colors[i]), name = map_set_name[set_label]))
            fig_wave.add_trace(go.Scatter(x = f_segment_wave_df["timestamp"], y = f_segment_wave_df["vals"], mode = "lines", opacity = 1, line = dict(width = 3, color = colors[i]), name = map_set_name[set_label]))
            
            fig_dist.add_trace(go.Histogram(x=f_segment_wave_df["vals"], xbins=dict(start=0, end=f_segment_wave_df["vals"].max(), size=7000),
                        marker_color=colors[i], opacity=0.7, name = map_set_name[set_label]))#, histnorm='probability'))
        
        fig_dist.update_layout(
                template = "plotly_dark",
                #bargap=0.1,
                width = 1500, height = 750,
                xaxis_range = [0, 150_000],
                yaxis_range = [0, 60]
            )


           # fig_wave.add_trace(go.Scatter(x = smooth_time_range, y = interp_df["vals"], mode = "lines", opacity = 1, line = dict(width = 3, color = colors[i]), name = map_set_name[set_label]))


        fig_wave.update_layout(template = "plotly_dark", width = 2500, height = 750)



        #fig_wave.write_image(f"animations\\tsne_fft_evol\\6\\{frame_nr:04}.png")
        #fig_tsne.write_image(f"animations\\tsne_fft_evol\\7\\{frame_nr:04}.png")
        frame_nr+=1


        frame_wave = fig_wave.to_image(format = "png")
        frame_tsne = fig_tsne.to_image(format = "png")
        frame_hist = fig_dist.to_image(format = "png")

        concat_img, _ = concat_images_vertical([Image.open(io.BytesIO(frame_wave)), Image.open(io.BytesIO(frame_hist))], [0,0,1000,0], [0,0,0,0])

        concat_img, _ = concat_images_horizontal([Image.open(io.BytesIO(frame_tsne)), concat_img], [0,0,150,0], [0,0,0,0])

        concat_img.save(f"animations\\tsne_fft_evol\\17\\{frame_nr:04}.png")
        frame_nr+=1



     #   fig.show()

def save_fft_tsne(df):
    df['PreciseTimeStamp'] = pd.to_datetime(df['PreciseTimeStamp'])
    df = df.sort_values(by='PreciseTimeStamp')
    df['PreciseTimeStamp'] = df['PreciseTimeStamp'].dt.floor('1S')
    fft_df, set_labels, map_set_name = plot_tsne_fft_ordered(df, save_data= True)


def compute_cluster_images(cluster_labels, fft_df, tsne_indexes_map, tsne_labels):
    cluster_figs = {l:go.Figure() for l in np.unique(cluster_labels)}
    
    for l in cluster_figs:
        cluster_figs[l].update_layout(template = "plotly_dark", width = 3500, height = 3500,
               # xaxis_range = [0, 150_000],
                yaxis_range = [0, 450_000]
            )
    print(len(cluster_labels))
    i=0
    for c_label, t_index, t_set_label in zip(cluster_labels, tsne_indexes_map, tsne_labels):
        i+=1
       # print(i)
        values = fft_df.at[t_index, f"{t_set_label}_approximated_signal"]
        
        #time_range = pd.date_range(start=fft_df.at[t_index, "time_start"], end=fft_df.at[t_index, "time_end"], freq='1S')
        
        cluster_figs[c_label].add_trace(go.Scatter(x = list(range(len(values))), y = values, mode = "lines" , line = dict(width = 0.3)))

    for l in cluster_figs:
        cluster_figs[l].write_image(f"visualizations\\cluster_images\\{l}.png")



def run_clsutering():
    fft_df = pd.read_parquet("data\\fft_df.parquet")
    with open('data\\map_set_name.pkl', 'rb') as pickle_file:
        map_set_name = pickle.load(pickle_file)
    big_matrix = np.load('data\\big_matrix.npy')
    tsne_transform = np.load('data\\tsne_transform.npy')
    tsne_indexes_map = np.load('data\\tsne_indexes_map.npy')
    tsne_labels = np.load('data\\tsne_labels.npy')





    tsne_df = pd.DataFrame({"x": tsne_transform[:, 0], "y": tsne_transform[:, 1], "z": tsne_transform[:, 2], "label" : tsne_labels})






    kmeans = KMeans(n_clusters=5, n_init = 1, max_iter = 300)
    kmeans.fit(big_matrix)
    cluster_labels = kmeans.labels_
    
   # dbscan = DBSCAN(eps=1000000, min_samples=1)
   # cluster_labels = dbscan.fit_predict(big_matrix)
   # print(np.unique(cluster_labels))
   # exit()
   # tsne_df["label"] = cluster_labels

    #set_labels = map_set_name.keys()
    compute_cluster_images(cluster_labels, fft_df, tsne_indexes_map, tsne_labels)
   # exit()
    colors = plotly.colors.sequential.Rainbow
    while len(colors) < len(np.unique(cluster_labels)):
        colors += colors

    fig = go.Figure()
    for i, set_label in enumerate(np.unique(cluster_labels)):
       # print(fft_df[f"{set_label}_values"])
        ftsne_df = tsne_df[tsne_df["label"] == set_label]
        print(set_label, len(ftsne_df))
        fig.add_trace(go.Scatter3d(x = ftsne_df["x"], y = ftsne_df["y"], z = ftsne_df["z"], marker = dict(size = 4, color= colors[i]), line = dict(color = colors[i]), mode = "markers",
             name = f"{set_label}"))
    
    # fig = go.Figure()
    # fig.add_trace(go.Scatter3d(x = tsne_transform[:, 0], y = tsne_transform[:, 1], z = tsne_transform[:, 2], marker = dict(size = 4, color= cluster_labels, colorscale = "rainbow"), line = dict(color = cluster_labels, colorscale = "rainbow")))



    # fig = go.Figure()
    # for i, set_label in enumerate(set_labels):
    #     ftsne_df = tsne_df[tsne_df["label"] == set_label]
    #     fig.add_trace(go.Scatter3d(x = ftsne_df["x"], y = ftsne_df["y"], z = ftsne_df["z"], marker = dict(size = 4, color= colors[i]), line = dict(color = colors[i]),
    #                             name = map_set_name[set_label]))
    
    
    # fig.show()
    # fig = go.Figure()
    # for i, set_label in enumerate(set_labels):
    #     fig.add_trace(go.Scatter3d(x = fft_df[f"{set_label}_xTSNE"], y = fft_df[f"{set_label}_yTSNE"], z = fft_df[f"{set_label}_zTSNE"], marker = dict(size = 4, color= colors[i]), line = dict(color = colors[i]),
    #                             name = map_set_name[set_label]))
    
    
    
    fig.update_layout(template = "plotly_dark")
    fig.show()






if __name__ == "__main__":    
    os.chdir(r"D:\programming\micro\latency")
    filters_list = ["region", "subscriptionId1", "operationName"]
    

   # df = pd.read_parquet(r"D:\programming\micro\latency\data\query2.parquet", engine = "pyarrow")
   # df = df[1000 :4000] #BUILT ANIMATIONS ON
   # save_fft_tsne(df)
    #df = df[50000-20000 : 50000+20000]
    #plot_tsne_fft_ordered(df, do_plot= True)
   # df = df[50000-20000 : 50000+20000]
    #df['PreciseTimeStamp'] = pd.to_datetime(df['PreciseTimeStamp'])
    #df = df.sort_values(by='PreciseTimeStamp')
    #df['PreciseTimeStamp'] = df['PreciseTimeStamp'].dt.floor('1S')
   
   # plot_evolution(df)
   # plot_set_evolution(df)
    run_clsutering()


#TODO:
    # DATA LOSS IN for t, latency in zip(f_wave_df["PreciseTimeStamp"], f_wave_df["e2EDurationInMilliseconds"]):
    # ZIP, nr latencies may be higher than the time interval, and if 2 happen in the same second, the next will be removed. aaa :(  and interval will be squashed


#lines overlapped for clusters, scatter
#heatmap of prob distr
#plot bigger distrib for entire user -> train hidden markov chain on it
#run nn to determine clusters -> should we overlap different customers?
#see distrib of different vm types for same user
